# base_state*base_model_alpha + (lora_state[i]*lora_scale[i]*lora_alpha[i]) + (part_state[k]*part_alpha[k])

pretrained_model: ''
prompt: ''
neg_prompt: 'lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry'
emb_dir: 'embs/'
out_dir: 'output/'
N_repeats: 1
clip_skip: 0
bs: 4
num: 1
seed: null
dtype: 'fp16'

condition: null

ex_input: {}

save:
  save_cfg: True
  image_type: png
  quality: 95
#  image_type: webp
#  quality: 75

offload: null
#offload:
#  max_VRAM: 8GiB
#  max_RAM: 30GiB
#  vae_cpu: False

#vae_optimize: null
vae_optimize:
  tiling: True
  slicing: False

interface:
  - _target_: hcpdiff.vis.DiskInterface
    show_steps: 0
    save_root: 'output/'

infer_args:
  width: 512
  height: 512
  guidance_scale: 7.5
  num_inference_steps: 50

new_components: {}

merge: null