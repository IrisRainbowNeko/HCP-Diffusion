_base_:
  - cfgs/train/dataset/base_dataset.yaml
  - cfgs/train/train_base.yaml
  - cfgs/train/tuning_base.yaml

lora_unet:
  -
    lr: 0.0006
    rank: 4
    alpha: 2
    layers:
       - 're:.*\.attn.?$'
       - 're:.*\.ff$'


train:
  train_steps: null
  train_epochs: 20

  optimizer:
    _target_: torch.optim.AdamW
    _partial_: True
    weight_decay: 0.1
    betas: [0.9, 0.99]

  scheduler:
    name: 'constant'
    num_warmup_steps: 0
    num_training_steps: 100000

model:
  pretrained_model_name_or_path: 'runwayml/stable-diffusion-v1-5'
  tokenizer_repeats: 1

data:
  dataset1:
    batch_size: 4
    cache_latents: True

    source:
      data_source1:
        img_root: 'imgs/'
        prompt_template: 'prompt_tuning_template/object.txt'
        caption_file: null # path to image captions (file_words)

        text_transforms:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: hcpdiff.utils.caption_tools.TagShuffle
            - _target_: hcpdiff.utils.caption_tools.TagErase
              p: 0.05
            - _target_: hcpdiff.utils.caption_tools.TemplateFill
              word_names:
                pt1: pt-cat1


    bucket:
      _target_: hcpdiff.data.bucket.RatioBucket.from_files # aspect ratio bucket
      target_area: ${hcp.eval:"512*768"}
      num_bucket: 10