_base_: [cfgs/train/dataset/base_dataset.yaml]

data:
  dataset_class:
    _target_: hcpdiff.data.TextImagePairDataset
    _partial_: True
    batch_size: 1
    cache_latents: True
    att_mask_encode: False
    loss_weight: 1.0

    source:
      data_source1:
        _target_: hcpdiff.data.source.Text2ImageAttMapSource
        img_root: 'imgs/db_class'
        prompt_template: 'prompt_tuning_template/object.txt'
        caption_file: null
        att_mask: null
        bg_color: [ 255, 255, 255 ] # RGB; for ARGB -> RGB

        word_names:
          pt1: ''

        text_transforms:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: hcpdiff.utils.caption_tools.TemplateFill
              word_names: ${....word_names}
    bucket:
      _target_: hcpdiff.data.bucket.FixedBucket
      target_size: [ 512, 512 ]